# breast_cancer_classifier.py

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import seaborn as sns
import numpy as np

# Device configuration
device = torch.device("cpu")  # or 'cuda' if available and desired

# Paths
train_dir = "breakhis_data/BreaKHis 400X/train"
test_dir = "breakhis_data/BreaKHis 400X/test"

# Transforms
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# Custom Dataset to include image paths
class ImageFolderWithPaths(datasets.ImageFolder):
    def __getitem__(self, index):
        data, target = super().__getitem__(index)
        path = self.samples[index][0]
        return data, target, path

# Load Data
train_data = ImageFolderWithPaths(train_dir, transform=transform)
test_data = ImageFolderWithPaths(test_dir, transform=transform)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# Model (Transfer Learning)
model = models.resnet18(pretrained=True)
model.fc = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(model.fc.in_features, 2)
)
model = model.to(device)

# Loss & Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# Training
for epoch in range(5):
    model.train()
    total_loss = 0
    for images, labels, _ in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}")

# Evaluation
model.eval()
all_preds, all_labels, all_paths = [], [], []
with torch.no_grad():
    for images, labels, paths in test_loader:
        outputs = model(images.to(device))
        preds = torch.argmax(outputs, 1).cpu()
        all_preds.extend(preds.numpy())
        all_labels.extend(labels.numpy())
        all_paths.extend(paths)

# Classification report
print(classification_report(all_labels, all_preds, target_names=train_data.classes))
print("ROC AUC Score:", roc_auc_score(all_labels, all_preds))

# Confusion matrix
cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt="d", xticklabels=train_data.classes, yticklabels=train_data.classes)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# Visualize Correct and Incorrect Predictions
def show_predictions(correct=True, max_images=5):
    count = 0
    for img_path, pred, true in zip(all_paths, all_preds, all_labels):
        if (pred == true) == correct:
            img = Image.open(img_path).convert("RGB")
            plt.imshow(img)
            plt.title(f"Pred: {train_data.classes[pred]}, True: {train_data.classes[true]}")
            plt.axis("off")
            plt.show()
            count += 1
        if count >= max_images:
            break

print("\n✅ Correct Predictions:")
show_predictions(correct=True)

print("\n❌ Incorrect Predictions:")
show_predictions(correct=False)
